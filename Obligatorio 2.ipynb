{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio 2 - Big Data Science\n",
    "\n",
    "Integrantes del grupo: Martín Brian - Joaquín Martínez\n",
    "\n",
    "Debajo de cada pregunta o tarea incluya las celdas necesarias para desarrolar la respuesta. Puede usar una o varias celdas de código o mark down (https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook)\n",
    "\n",
    "Para entregar, renombrar este notebook como \"Obligatorio 2 - Apellido1 - Apellido 2 - Apellido 3\" con los apellidos de los miembros del grupo. Un solo integrante del grupo debe realizar la entrega. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargar los datos del Obligatorio 1, de entrenamiento (.data) y validación (.test) en spark dataframes (distintos). Los nombres de las columnas deben corresponder a los especificados en \"Attribute Information\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", FloatType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education-num\", FloatType(), True),\n",
    "    StructField(\"marital-status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital-gain\", FloatType(), True),\n",
    "    StructField(\"capital-loss\", FloatType(), True),\n",
    "    StructField(\"hours-per-week\", FloatType(), True),\n",
    "    StructField(\"native-country\", StringType(), True),\n",
    "    StructField(\"salary\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos los archivos\n",
    "df_data = spark.read.csv(\"./adult.data\", header=False,schema=schema)\n",
    "df_test = spark.read.csv(\"./adult.test\", header=True,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       age          workclass    fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516.0    Bachelors           13.0   \n",
       "1       50   Self-emp-not-inc   83311.0    Bachelors           13.0   \n",
       "2       38            Private  215646.0      HS-grad            9.0   \n",
       "3       53            Private  234721.0         11th            7.0   \n",
       "4       28            Private  338409.0    Bachelors           13.0   \n",
       "...    ...                ...       ...          ...            ...   \n",
       "32556   27            Private  257302.0   Assoc-acdm           12.0   \n",
       "32557   40            Private  154374.0      HS-grad            9.0   \n",
       "32558   58            Private  151910.0      HS-grad            9.0   \n",
       "32559   22            Private  201490.0      HS-grad            9.0   \n",
       "32560   52       Self-emp-inc  287927.0      HS-grad            9.0   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male        2174.0           0.0            40.0   United-States   \n",
       "1         Male           0.0           0.0            13.0   United-States   \n",
       "2         Male           0.0           0.0            40.0   United-States   \n",
       "3         Male           0.0           0.0            40.0   United-States   \n",
       "4       Female           0.0           0.0            40.0            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female           0.0           0.0            38.0   United-States   \n",
       "32557     Male           0.0           0.0            40.0   United-States   \n",
       "32558   Female           0.0           0.0            40.0   United-States   \n",
       "32559     Male           0.0           0.0            20.0   United-States   \n",
       "32560   Female       15024.0           0.0            40.0   United-States   \n",
       "\n",
       "       salary  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721.0</td>\n      <td>11th</td>\n      <td>7.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>27</td>\n      <td>Private</td>\n      <td>257302.0</td>\n      <td>Assoc-acdm</td>\n      <td>12.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Tech-support</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>38.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>154374.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>151910.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Widowed</td>\n      <td>Adm-clerical</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>22</td>\n      <td>Private</td>\n      <td>201490.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>52</td>\n      <td>Self-emp-inc</td>\n      <td>287927.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>15024.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n<p>32561 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 age workclass        fnlwgt education  education-num  \\\n",
       "count   32561.000000     32561  3.256100e+04     32561   32561.000000   \n",
       "unique           NaN         9           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     22696           NaN     10501            NaN   \n",
       "mean       38.581647       NaN  1.897784e+05       NaN      10.080679   \n",
       "std        13.640433       NaN  1.055500e+05       NaN       2.572720   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.178270e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.783560e+05       NaN      10.000000   \n",
       "75%        48.000000       NaN  2.370510e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.484705e+06       NaN      16.000000   \n",
       "\n",
       "             marital-status       occupation relationship    race    sex  \\\n",
       "count                 32561            32561        32561   32561  32561   \n",
       "unique                    7               15            6       5      2   \n",
       "top      Married-civ-spouse   Prof-specialty      Husband   White   Male   \n",
       "freq                  14976             4140        13193   27816  21790   \n",
       "mean                    NaN              NaN          NaN     NaN    NaN   \n",
       "std                     NaN              NaN          NaN     NaN    NaN   \n",
       "min                     NaN              NaN          NaN     NaN    NaN   \n",
       "25%                     NaN              NaN          NaN     NaN    NaN   \n",
       "50%                     NaN              NaN          NaN     NaN    NaN   \n",
       "75%                     NaN              NaN          NaN     NaN    NaN   \n",
       "max                     NaN              NaN          NaN     NaN    NaN   \n",
       "\n",
       "        capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "count   32561.000000  32561.000000    32561.000000           32561   32561  \n",
       "unique           NaN           NaN             NaN              42       2  \n",
       "top              NaN           NaN             NaN   United-States   <=50K  \n",
       "freq             NaN           NaN             NaN           29170   24720  \n",
       "mean     1077.648804     87.303833       40.437454             NaN     NaN  \n",
       "std      7385.291992    402.960205       12.347429             NaN     NaN  \n",
       "min         0.000000      0.000000        1.000000             NaN     NaN  \n",
       "25%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       "50%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       "75%         0.000000      0.000000       45.000000             NaN     NaN  \n",
       "max     99999.000000   4356.000000       99.000000             NaN     NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32561.000000</td>\n      <td>32561</td>\n      <td>3.256100e+04</td>\n      <td>32561</td>\n      <td>32561.000000</td>\n      <td>32561</td>\n      <td>32561</td>\n      <td>32561</td>\n      <td>32561</td>\n      <td>32561</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561</td>\n      <td>32561</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>15</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>42</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Private</td>\n      <td>NaN</td>\n      <td>HS-grad</td>\n      <td>NaN</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>22696</td>\n      <td>NaN</td>\n      <td>10501</td>\n      <td>NaN</td>\n      <td>14976</td>\n      <td>4140</td>\n      <td>13193</td>\n      <td>27816</td>\n      <td>21790</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29170</td>\n      <td>24720</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>38.581647</td>\n      <td>NaN</td>\n      <td>1.897784e+05</td>\n      <td>NaN</td>\n      <td>10.080679</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1077.648804</td>\n      <td>87.303833</td>\n      <td>40.437454</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.640433</td>\n      <td>NaN</td>\n      <td>1.055500e+05</td>\n      <td>NaN</td>\n      <td>2.572720</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7385.291992</td>\n      <td>402.960205</td>\n      <td>12.347429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17.000000</td>\n      <td>NaN</td>\n      <td>1.228500e+04</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>28.000000</td>\n      <td>NaN</td>\n      <td>1.178270e+05</td>\n      <td>NaN</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>37.000000</td>\n      <td>NaN</td>\n      <td>1.783560e+05</td>\n      <td>NaN</td>\n      <td>10.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>48.000000</td>\n      <td>NaN</td>\n      <td>2.370510e+05</td>\n      <td>NaN</td>\n      <td>12.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>45.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>90.000000</td>\n      <td>NaN</td>\n      <td>1.484705e+06</td>\n      <td>NaN</td>\n      <td>16.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99999.000000</td>\n      <td>4356.000000</td>\n      <td>99.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_data.toPandas().describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# Limpiamos puntos en la columna salario\n",
    "df_test = df_test.withColumn('salary', regexp_replace('salary', '<=50K.', '<=50K'))\n",
    "df_test = df_test.withColumn('salary', regexp_replace('salary', '>50K.', '>50K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Seleccionar un conjunto relevante de 5 atributos y crear un Spark Pipeline en el que el estimator sea un DecisionTreeClassifier (https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier). Puede utilizar libremente los transformers/estimators de Spark para realizar ingeniería de atributos (StringIndexer, OneHotEncoding, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Bucketizer, OneHotEncoder\n",
    "\n",
    "def get_indexed_name(name):\n",
    "    return f\"{name}_index\"\n",
    "\n",
    "def get_onehot_name(name):\n",
    "    return f\"{name}_onehot\"\n",
    "\n",
    "chosen_columns = [\"age\", \"sex\", \"education-num\", \"occupation\", \"hours-per-week\"]\n",
    "\n",
    "string_type_name = StringType.typeName()\n",
    "chosen_columns_dtypes = df_data.select(chosen_columns).dtypes\n",
    "strings_to_index = list(filter(lambda column: dict(chosen_columns_dtypes)[column] == string_type_name, chosen_columns))\n",
    "string_indexers = [StringIndexer(inputCol=column, outputCol=get_indexed_name(column)) for column in strings_to_index]\n",
    "\n",
    "encoder_output=[get_onehot_name(string) for string in strings_to_index]\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=[get_indexed_name(string) for string in strings_to_index],\n",
    "                        outputCols=encoder_output)\n",
    "\n",
    "splits = [0, 25, 40, 60, float(\"inf\")]\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"age\", outputCol=\"age_bucketed\")\n",
    "\n",
    "splits = [0, 25, 50, 75, float(\"inf\")]\n",
    "bucketizer_hours = Bucketizer(splits=splits, inputCol=\"hours-per-week\", outputCol=\"hours-per-week_bucketed\")\n",
    "\n",
    "chosen_numeric=set(chosen_columns)-set(strings_to_index)-set(\"age\")-set(\"hours-per-week\")\n",
    "\n",
    "chosen = list(chosen_numeric)\n",
    "chosen.extend(encoder_output)\n",
    "chosen.append(\"age_bucketed\")\n",
    "chosen.append(\"hours-per-week_bucketed\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=chosen, outputCol=\"vector_col\") \n",
    "salary_indexer = StringIndexer(inputCol=\"salary\", outputCol=\"salary_indexed\")\n",
    "\n",
    "# Decision tree parameters (para poder ajustarlo)\n",
    "\"\"\"DecisionTreeClassifier(*, featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', seed=None, weightCol=None, leafCol='', minWeightFractionPerNode=0.0)\"\"\"\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"salary_indexed\", featuresCol=\"vector_col\", maxDepth=8)\n",
    "\n",
    "stages = string_indexers\n",
    "stages.extend([salary_indexer, encoder, bucketizer, bucketizer_hours, assembler, dt])\n",
    "pipeline = Pipeline(stages=stages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Hacer el fit del pipeline con los datos de entrenamiento. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------------+\n",
      "|prediction|salary_indexed|\n",
      "+----------+--------------+\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           1.0|\n",
      "|       0.0|           1.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           0.0|\n",
      "|       1.0|           1.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           1.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           0.0|\n",
      "|       0.0|           1.0|\n",
      "+----------+--------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "hits/total: 0.8143484536715703\n",
      "   prediction  salary_indexed  count\n",
      "0         1.0             1.0   3202\n",
      "1         0.0             1.0   4639\n",
      "2         1.0             0.0   1406\n",
      "3         0.0             0.0  23314\n",
      "\n",
      "\n",
      "\n",
      "hits/total: 0.8075671027578158\n",
      "   prediction  salary_indexed  count\n",
      "0         1.0             1.0   1501\n",
      "1         0.0             1.0   2345\n",
      "2         1.0             0.0    788\n",
      "3         0.0             0.0  11647\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_data)\n",
    "\n",
    "predictions_in_training = model.transform(df_data)\n",
    "predictions = model.transform(df_test)\n",
    "\n",
    "predictions.select([\"prediction\", \"salary_indexed\"]).show(15)\n",
    "\n",
    "def get_confusion_matrix(predictions):\n",
    "    confusion=predictions.groupBy(\"prediction\", 'salary_indexed').count()\n",
    "    confusion_collected = confusion.collect()\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    for row in confusion_collected:\n",
    "        total += row[2]\n",
    "        if row[0]==row[1]:\n",
    "            hits += row[2]\n",
    "\n",
    "    print(f\"hits/total: {hits/total}\")\n",
    "    return confusion.toPandas()\n",
    "\n",
    "print(get_confusion_matrix(predictions_in_training), end='\\n'*4)\n",
    "print(get_confusion_matrix(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Graficar la curva ROC utilizando los datos de validación (sin usar el paquete de evluación de Spark pyspark.ml.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "roc_points_false_positive_rate = []\n",
    "roc_points_true_positive_rate = []\n",
    "\n",
    "threshold = [x / 100 for x in range(0, 101, 5)]\n",
    "\n",
    "data = predictions.select(\"prediction\", \"salary_indexed\", \"probability\").collect()\n",
    "\n",
    "data.toPandas()\n",
    "\n",
    "def get_positive_with_threshold(threshold, data):\n",
    "    positives = 0\n",
    "    for row in data:\n",
    "        if row[\"probability\"][0] > threshold:\n",
    "            positives +=\n",
    "\n",
    "\n",
    "# for value in threshold:\n",
    "#     for row in data:\n",
    "#         return spark.sql(f\"select count(*) from data where occupation='{occupation}' and education='{education}' and output='{output}'\")\n",
    "\n",
    "    # if row.prediction == 1.0 and row.salary_indexed == 1.0:\n",
    "    #     true_positive += 1\n",
    "    # elif row.prediction == 1.0:\n",
    "    #     false_positive += 1\n",
    "    # elif row.prediction == 0.0 and row.salary_indexed == 1.0:\n",
    "    #     true_negative += 1\n",
    "    # else:\n",
    "    #     false_negative += 1\n",
    "    \n",
    "    # try:\n",
    "    #     true_positive_rate = true_positive/(true_positive+false_negative)\n",
    "    # except ZeroDivisionError:\n",
    "    #     true_positive_rate = 0\n",
    "    # try:\n",
    "    #     false_positive_rate = false_positive/(false_positive+true_negative)\n",
    "    # except ZeroDivisionError:\n",
    "    #     false_positive_rate = 0\n",
    "\n",
    "    # roc_points_true_positive_rate.append(true_positive_rate)\n",
    "    # roc_points_false_positive_rate.append(false_positive_rate)\n",
    "    \n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(roc_points_false_positive_rate, roc_points_true_positive_rate)\n",
    "\n",
    "# plt.xlabel('false positive rate')\n",
    "# plt.ylabel('true positive rate')\n",
    "\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "# plt.show()\n",
    "\n",
    "# predictions.select(\"prediction\", \"salary_indexed\", \"vector_col\", \"probability\").toPan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Escribir dos funciones train() y predict() que creen el arbol de acuerdo a la metodología vista en clase (utilizando entropía como métrica de homogeneidad de clases).\n",
    "```\n",
    "def train(train_dataframe):\n",
    "    '''\n",
    "    @return devuelve una estructura de datos que representa el árbol de decision\n",
    "    '''\n",
    "     pass        \n",
    "```\n",
    "\n",
    "```\n",
    "def predict(tree, train_dataframe)\n",
    "    '''\n",
    "    @param tree la estructura de datos que representa el árbol de decisión.\n",
    "    @ return un dataframe con todos los datos de train_dataframe con una columna adicional que representa la probabilidad de que el income sea >50K. \n",
    "    '''\n",
    "    pass\n",
    "```    \n",
    "Ejemplo de uso:\n",
    "\n",
    "```\n",
    "tree = train(train_dataframe)\n",
    "predictions_df = predict(tree, train_dataframe)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>[Extra credit y alumnos masters]</i>\n",
    "    \n",
    "5.  Mejorar la implementación de su algoritmo evitando hacer el split cuando no se logra un mínimo de Information Gain ( https://en.wikipedia.org/wiki/Information_gain_in_decision_trees   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}